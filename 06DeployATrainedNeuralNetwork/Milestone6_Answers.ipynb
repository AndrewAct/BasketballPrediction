{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Milestone6_Answers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPrHWUve21jUBC92R/FNVxs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehennis/Manning/blob/master/Milestone6_Answers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw7ST8euabiY",
        "colab_type": "text"
      },
      "source": [
        "# Deploying a trained network  \n",
        "\n",
        "This will be slightly different from the first 5 milestones in that we are targeting JavaScript and the web.  \n",
        "* The first section will be using Python to convert the DataFrame into a JS file.  \n",
        "* The second part will be using Python to create an h5 model.  \n",
        "* The final part will be adding the HTML and JavaScript code around the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYaJBMouIw1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#Load the data set with all of the calculated values\n",
        "column_names = ['Date','HomeTeam','HomeScore','AwayTeam','AwayScore',\n",
        "                'HomeScoreAverage','HomeDefenseAverage','AwayScoreAverage','AwayDefenseAverage',\n",
        "                'Result']\n",
        "\n",
        "games_csv = 'https://liveproject-resources.s3.amazonaws.com/other/deeplearningbasketballscores/Games-Calculated.csv'\n",
        "all_data = pd.read_csv(games_csv, header=None, names=column_names)\n",
        "\n",
        "#Load the teams data set\n",
        "team_columns = ['Conference','Team']\n",
        "\n",
        "teams_csv = 'https://liveproject-resources.s3.amazonaws.com/other/deeplearningbasketballscores/Teams.csv'\n",
        "teams = pd.read_csv(teams_csv, header=None, names=team_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQK2G9y9j54g",
        "colab_type": "text"
      },
      "source": [
        "## Create a JavaScript Array  \n",
        "\n",
        "In this section, we are going to grab the values from the current season (as stated in the assignment, this would normally be done during the season and incremented each day but for this project we will just use the final stats) and export those to a text file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dr9K3I9aYj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find the averages\n",
        "def FindAverages(df_current, team_name, col_name, off_avg, def_avg):\n",
        "  row = df_current[(df_current[col_name] == team_name)][-1:]\n",
        "  #If the team can't be found return 0s\n",
        "  if row.empty:\n",
        "      return 0,0\n",
        "  return row[off_avg].values[0], row[def_avg].values[0]\n",
        "  \n",
        "def FindHomeAverages(df, team_name):\n",
        "  return FindAverages(df, team_name,'HomeTeam','HomeScoreAverage','HomeDefenseAverage')\n",
        "\n",
        "def FindAwayAverages(df, team_name):\n",
        "  return FindAverages(df, team_name,'AwayTeam','AwayScoreAverage','AwayDefenseAverage')\n",
        "\n",
        "def PrintCurrentStats(file1, df, teams):\n",
        "  #Grab each team and find their home and away stats\n",
        "  file1.write('var current_stats = [\\n')\n",
        "  for index, row in teams.iterrows():\n",
        "      team_name = row['Team']\n",
        "      home_off, home_def = FindHomeAverages(df, team_name)\n",
        "      away_off, away_def = FindAwayAverages(df, team_name)\n",
        "      # Fix the Quotes\n",
        "      if( \"'\" in team_name):\n",
        "        team_name = team_name.replace(\"\\'\",\"\\\\'\");\n",
        "      #Print them so that I can use their values in a JavaScript file\n",
        "      file1.write('[ \\'%s\\',%s,%s,%s,%s ],\\n' % (team_name,home_off, home_def, away_off, away_def))\n",
        "  file1.write('];')\n",
        "\n",
        "def PrintConferenceAndTeams(file1):\n",
        "  file1.write(\"var conf = ['Select Conference','America East','American Athletic Conference','Atlantic 10','Atlantic Coast','Atlantic Sun','Big 12','Big East','Big Sky',\");\n",
        "  file1.write(\"'Big South','Big Ten','Big West','Colonial Athletic','Conference USA','Horizon','Ivy League','Metro Atlantic Athletic','Mid-American','Mid-Eastern',\");\n",
        "  file1.write(\"'Missouri Valley','Mountain West','Northeast','Ohio Valley','Pac-12','Patriot League','Southeastern','Southern','Southland','Southwestern Athletic',\");\n",
        "  file1.write(\"'Summit League','Sun Belt','West Coast','Western Athletic'];\");\n",
        "  file1.write('\\n');\n",
        "\n",
        "  file1.write(\"//Teams teamDictionary\\n\")\n",
        "  file1.write(\"var teamDict = new Object();\\n\")\n",
        "  for index, row in teams.iterrows():\n",
        "    team_name = row['Team']\n",
        "    # Fix the Quotes\n",
        "    if( \"'\" in team_name):\n",
        "      team_name = team_name.replace(\"\\'\",\"\\\\'\");\n",
        "    conference = row['Conference']\n",
        "    file1.write(\"teamDict['%s'] = '%s';\\n\" % (team_name,conference));\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyJalKfFJqKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the file\n",
        "file1 = open('Teams.js','w')\n",
        "\n",
        "# Write Conference and Teams for the dropdowns\n",
        "PrintConferenceAndTeams(file1);\n",
        "\n",
        "#Grab Current Season\n",
        "s2018 = all_data[(all_data['Date'] > '2018-11-01') & (all_data['Date'] < '2019-04-15')].copy()\n",
        "PrintCurrentStats(file1, s2018, teams)\n",
        "\n",
        "\n",
        "file1.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFi5zw9bPDAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Google Colab code to download\n",
        "from google.colab import files\n",
        "files.download('Teams.js')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6UOt8XjZgbj",
        "colab_type": "text"
      },
      "source": [
        "## Creating and deploying a trained model  \n",
        "\n",
        "### Convert from Keras to TF.JS\n",
        "\n",
        "This section we will take our trained model from milestone 5 and convert it to a format that our web site can consume."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdChyDlqhkEv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "cf718898-0da0-4528-9dbc-922f301adc4f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QARGQOS-ifGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load h5\n",
        "\n",
        "# TODO: Fix this once it gets uploaded\n",
        "model = keras.models.load_model('/content/gdrive/My Drive/Colab Notebooks/deeplearning-manning.h5')\n",
        "\n",
        "# Recompile Model\n",
        "opt = keras.optimizers.RMSprop()\n",
        "m = [\n",
        "      keras.metrics.MeanAbsoluteError(),\n",
        "      keras.metrics.Accuracy(),\n",
        "      keras.metrics.MeanSquaredError()\n",
        "]\n",
        "l = keras.losses.MeanSquaredError()\n",
        "\n",
        "model.compile(loss=l, optimizer=opt, metrics=m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPFnGvMWjStz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Need to install TensorFlow.JS\n",
        "!pip install tensorflowjs\n",
        "\n",
        "import tensorflowjs as tfjs\n",
        "print(tfjs.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lQHcbCxlTlQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a975a68e-ecad-48d9-ad4d-0cf8f475b4aa"
      },
      "source": [
        "tfjs.converters.save_keras_model(model,'dl-manning')\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflowjs/converters/keras_h5_conversion.py:122: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  return h5py.File(h5file)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdnHdRMzmA00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Google Colab code to download\n",
        "from google.colab import files\n",
        "files.download('dl-manning/model.json')\n",
        "files.download('dl-manning/group1-shard1of1.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OHhNNs2njSk",
        "colab_type": "text"
      },
      "source": [
        "### Create the JavaScript files to access the model  \n",
        "\n",
        "#TODO: Figure out how to handle this. Currently, WebSite.zip has the files"
      ]
    }
  ]
}